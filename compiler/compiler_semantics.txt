it involves checking names and types.
it has to deal with declarations and scopes.

Semantic analyser may change the program's representation from a tree to some form of intermediate language.

Strong typing can help avoidn some runtime errors. 

It is always preferable to move as much error detection as possible from runtime to compile time, finding errors at the earliest possible stage. 

As soon as user defined types are introducede,a new approach is needed. 
For example, typedef feature in C allows arbitrarilt complex types to be defined and named. 
Here, the type information can be represented as an abstract syntax tree of the type specifier linked to by th type name's entry in the symbole table.

TYPE RULES

Static typing 

Dynamic typing = type of data stored in a variable can change during that variable's existence. 
    This means that not all type checking will be done during compile time.
    This implies that there implementation of the language has to support the association of a type with each varaible at runtime so that checking code, generated by the compiler or included in the interpreter, can ensure that the type rules are being adhered to.
    clearly there is a runtime overhead in doing this.

    To maintain strong type checking, not all checking is possible at compile time and so at least some runtime checking is required too.

     During the semantic analysis phase in statically types languages that a type for the operator can be selected.
     In dynamically types languages the operatir choice may well have to be delayes until runtime.

    TYPES are said to have NAME EQUIVALENCE if they have the same name and 
    STRUCTURAL EQUIVALENCE if they have the same structure. 

TYPE CHECKING 
    An intuitive way of managing type checking in the semantic analysis phase is to traverse the abstract syntax tree, tagging nodes in the process.

    the semantic analyser will start at the root node containing the assignment operator and perform a recurcise post-order traversal of the tree, tagging nodes as it goes. 

    the + node is the examinded and a decision has to be made whether this operator applied to a real and int is valid and if so, how it should be interpreted. 

    Assuming convential mixed-mode arithmetic is permitted, we have to introdice a new node to convert int i to a real values and the tag the + node with real.

    This tree trversal/annotaion process is driven by the type rules of the language being compiled.
    Each node requiring a type will be tagged with a type derived from the types of its children according to the type rules. 

    And tree modifications will be made where necessary.

    Separating this task from the syntax analyser makes the compiler's code much simpler and more maintainable.

TYPE RULES
    Rukes depend on the details defined in the language specification. 
    The introduction of other operators may well benefit the language, but the semantics of operators such as multiply and divide may be more difficult to envisage when manipulating dates.

STORAGE MANAGEMENT
    Within syntax and semantic analysis, decisions have to be made concerning the runtime representations of data and language-supported data structures. 
    
    Target machine-dependent details are better left until the code generation phase but the intermediate code to be generated by the semantic analyser really needs some sort of data storage model which can be mapped later to physical storage of the target machine.

ACCESS TO SIMPLE VARIABLES 
    variable names have to be mapped to physical storage locatioons.
    one or more runtime storage area, each being a contiguous area of memory, pointed to and hence identified by one or more target machine registers.

    The sematic analyis phase can associate a single offset values for each variabel and these offsets can be saved in an abstract syntax tree and hence in the intermediate representation each time a variable is used.
    
    Dealing with different memory-sized data representations is not a problem because the type information is stored in the symbol table and the tree and this can be translated into a memory size indication symbol table and the tree and this can then be translated into a target machine offset during code generation. 

    Instead, it also may be possibel to perform translation of text variable names into offsets in the syntax analyser, allocating space as variables are declared. 

FUNCTIONS

When a function is invoked, then memory space has to be available fot the storage of local vaiables declared in that function and also for the storage of the function's arguments.
when recursive function calls re permitted, static space allocation will not be adequate since new space has to be allocated for local variables on each recursive function calls are permitted, static space allocation will not be adequate since 
new space has to be allocated for local variables on each recusive call and it is in genral impossibe to predict in advance the actual maximum depth of recursion. 

Dynamic allocation scheme is required. The usual way of implementing this via a stack. 

Further complications arise in lnguages such as pascal where there is nested functioon defintiions.
Here you need multiple pointers to the stack.

Assuming that the bastract syntax tree makes use of nodes directlty representing array access, the semantic analyser could expand these nodes to represent this full address calculation process. 

ARRAY BOUND CHECKING 
    The addition of this checking code can be done by modifying the tree, dring the generation of the intermediate representation or later during target code generation. 
    The structure can be referenced as a whole while retaining access to individual fields. 

STRUCTURES AND UNIONS 

ATRIBUTE GRAMMARS 
    AN attribute is said to be synthesised if ots value is computed from data in the node itself and from data from that node's children. 

    Inherited attributes use data from or via the node's parents as well as from the node itself.
     This allows for context sensitive analysis to be formalised.

STATIC SINGLE ASSIGNMENT FORM 
    it just defines som structuring rules that can be applies to an IR such as three-address code so that the data flow information is made explicit.
    phi -function to indicate the meeting of control flow pahs and the result is chosen accordung to which variable definition(the most dominating) was made in the control flow path most recently executed. 
    
    implementation of the phi-function can be done by ensuring that allthe varibales of the phi-function share the same register or storage location or by ensuring that appropriate register copies are made. 
     All this additional complexity is justified by the fact that the data dependence information embedded in SSA is necessary for implementation of a wide range of optimisations. 


CONTROL FLOW GRAPH 
    Is a directed graph made up on nodes and edges with the edges representing possible paths of execution. 
    Each node represents either a single instruction or a basic block . 
   
    A basic block is an instruction sequence with a single entry point at the first instruction and an exit point at the last instruction. 

    Any jump (conditional or unconditional) instruction must be the last instruction in a block.
    If a blockend with conditional jump, there are two edges coming out of the node representing that block.

DATA DEPENDENCE GRAPHS 
    The data dependence graph for this trivial example would contain three nodes, one for each assignment, with an edge from node 1 to node 3. 
    This implies that the operation in node 1 has to be completed before performing the operation of node 3. 
    Nothing is said about when the operation in node 2 should be performed. 
    So this representation is ni general incomplete in the program's control flow is not uniquely specified by the data dependence graph. 

    The data dependence graph onl;y imposes a partial ordering on the statements or instructions. 

    But this structire can be useful when performing various specific optimising transforms such as parallelism detection and instruction scheduling. 
    data dependence information is implicitly encoded in SSA-style representations and so if an SSA-based IR is used, adding extra data dependence structures may not be quite so useful. 
     
     To allow the IR to provide more comprehensive information, the program dependence graph was proposed. 
     Which contains both control and data flow information, with node representation statements, predicate expressions or regions.

TRANSLATION TO THE IR 
    it is clear that there are no predefined "output"
    There are infinitely many semantically correct translations that could be produced from the abstract syntax tree. 

    These different translations will have different costs in terms of number of IR instructions. 

    PROPOSOLS AND CONSEQUENCES:
        1. There is no pressing need to do optimisation in this stage. 
        2.The generated code can be profligate with its use of temporary variables. 
            The code generator can assign these temporary variables to target machine registers or main storage locations.
        3. It is wrong to deal with each tree node independently. It is not esssential to examine the parent/child contect of each node to generate better code. 
        4. You could make use of symbolic names for labels and functions rather than absolute or relative addresses, aiming for an assembler-like language rather than machin code-like language. 
            Avoid references to the symbol table so that access to the symbol table does not need to be carried forward into the compiler's back-end.
        5. Try to maintain machine independence. 
    
FUNCTIONS 
    The parser constructs a linked list of pointers to all the functions declared in the DL programs. 
    There is a node for each function in this separate abstract syntax tree 
    and in this node is an identification of the 
    symbol table entry for the function
     together with a pointer to the tree for the block defining the code for the function. 

    The number of arguments is placed in the symbol table so that when the function is called, the number of arguments providede in the call can be compared with the number of arguments in the definition. 
    
    GENERATING CODE FOR EACH FUNCTION 
        the code needs to start with an identification of the fucntion name, and this is followed by the code for the function itself.
        This is total size of all variables declared within the function.
        The total number of variables declared within a function 
        if the function or the main program calls another function, knowledge of this size value is essential because the stack pointer(sp)
        has to be incremented by this value to point to the space available for the local variables of the function being called.

        The size value is usually stored in the symbol tabel, but it would be convenient to have the value available at the start of the IR code

        For the case of the DL compiler, the code for the function is preceded by a line starting with a colon character follwoed by the name of the function being defined, followed by the size of the local variables for that function enclosed in parentheses. 

        2. How to return the results to the caller of the function. 

            A convenient way of managing this is to reserve a temporary register for the entire compilation and this register is always assumed to contain the result from the last function call.

        What happens with a DL function that finishes without having executed a return instruction?
        The specification of DL language does not specify what to do. 
        SSo we take the easy way ouyt by assuming that all functions should end with the code 
            r0 = 0
            return 

        A value of 0 is returned if control falls through the end of a function without having executed an explicit return instruction 

        